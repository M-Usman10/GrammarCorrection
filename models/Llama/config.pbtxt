name: "Llama"
backend: "python"

max_batch_size: 8  # Supports up to 8 simultaneous commands

input [
  {
    name: "INPUT"
    data_type: TYPE_STRING
    dims: [ -1 ]  # Supports batch dimension and variable-length input
  }
]

output [
  {
    name: "OUTPUT"
    data_type: TYPE_STRING
    dims: [ -1 ]
  }
]